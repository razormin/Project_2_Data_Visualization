{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GitHub API to Produce Charts on Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Total repositories: 7427172\n",
      "Repositories returned: 30\n",
      "\n",
      "Selected info about the first repository:\n",
      "Name:  system-design-primer\n",
      "Owner:  donnemartin\n",
      "Stars:  135451\n",
      "Repository:  https://github.com/donnemartin/system-design-primer\n",
      "Created:  2017-02-26T16:15:28Z\n",
      "Updated:  2021-06-18T23:38:49Z\n",
      "Description:  Learn how to design large-scale systems. Prep for the system design interview.  Includes Anki flashcards.\n",
      "\n",
      "Selected info about each repository:\n",
      "\n",
      "Name:  system-design-primer\n",
      "Owner:  donnemartin\n",
      "Stars:  135451\n",
      "Repository:  https://github.com/donnemartin/system-design-primer\n",
      "Description:  Learn how to design large-scale systems. Prep for the system design interview.  Includes Anki flashcards.\n",
      "\n",
      "Name:  public-apis\n",
      "Owner:  public-apis\n",
      "Stars:  131844\n",
      "Repository:  https://github.com/public-apis/public-apis\n",
      "Description:  A collective list of free APIs\n",
      "\n",
      "Name:  Python\n",
      "Owner:  TheAlgorithms\n",
      "Stars:  110466\n",
      "Repository:  https://github.com/TheAlgorithms/Python\n",
      "Description:  All Algorithms implemented in Python\n",
      "\n",
      "Name:  awesome-python\n",
      "Owner:  vinta\n",
      "Stars:  99667\n",
      "Repository:  https://github.com/vinta/awesome-python\n",
      "Description:  A curated list of awesome Python frameworks, libraries, software and resources\n",
      "\n",
      "Name:  youtube-dl\n",
      "Owner:  ytdl-org\n",
      "Stars:  96539\n",
      "Repository:  https://github.com/ytdl-org/youtube-dl\n",
      "Description:  Command-line program to download videos from YouTube.com and other video sites\n",
      "\n",
      "Name:  thefuck\n",
      "Owner:  nvbn\n",
      "Stars:  62548\n",
      "Repository:  https://github.com/nvbn/thefuck\n",
      "Description:  Magnificent app which corrects your previous console command.\n",
      "\n",
      "Name:  django\n",
      "Owner:  django\n",
      "Stars:  58027\n",
      "Repository:  https://github.com/django/django\n",
      "Description:  The Web framework for perfectionists with deadlines.\n",
      "\n",
      "Name:  keras\n",
      "Owner:  keras-team\n",
      "Stars:  51551\n",
      "Repository:  https://github.com/keras-team/keras\n",
      "Description:  Deep Learning for humans\n",
      "\n",
      "Name:  httpie\n",
      "Owner:  httpie\n",
      "Stars:  51085\n",
      "Repository:  https://github.com/httpie/httpie\n",
      "Description:  As easy as /aitch-tee-tee-pie/ 🥧 Modern, user-friendly command-line HTTP client for the API era. JSON support, colors, sessions, downloads, plugins & more. https://twitter.com/httpie\n",
      "\n",
      "Name:  awesome-machine-learning\n",
      "Owner:  josephmisiti\n",
      "Stars:  50433\n",
      "Repository:  https://github.com/josephmisiti/awesome-machine-learning\n",
      "Description:  A curated list of awesome Machine Learning frameworks, libraries and software.\n",
      "\n",
      "Name:  ansible\n",
      "Owner:  ansible\n",
      "Stars:  48741\n",
      "Repository:  https://github.com/ansible/ansible\n",
      "Description:  Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.\n",
      "\n",
      "Name:  transformers\n",
      "Owner:  huggingface\n",
      "Stars:  47414\n",
      "Repository:  https://github.com/huggingface/transformers\n",
      "Description:  🤗Transformers: State-of-the-art Natural Language Processing for Pytorch, TensorFlow, and JAX.\n",
      "\n",
      "Name:  scikit-learn\n",
      "Owner:  scikit-learn\n",
      "Stars:  46152\n",
      "Repository:  https://github.com/scikit-learn/scikit-learn\n",
      "Description:  scikit-learn: machine learning in Python\n",
      "\n",
      "Name:  requests\n",
      "Owner:  psf\n",
      "Stars:  45474\n",
      "Repository:  https://github.com/psf/requests\n",
      "Description:  A simple, yet elegant HTTP library.\n",
      "\n",
      "Name:  core\n",
      "Owner:  home-assistant\n",
      "Stars:  43722\n",
      "Repository:  https://github.com/home-assistant/core\n",
      "Description:  :house_with_garden: Open source home automation that puts local control and privacy first\n",
      "\n",
      "Name:  HelloGitHub\n",
      "Owner:  521xueweihan\n",
      "Stars:  43356\n",
      "Repository:  https://github.com/521xueweihan/HelloGitHub\n",
      "Description:  :octocat: 分享 GitHub 上有趣、入门级的开源项目\n",
      "\n",
      "Name:  scrapy\n",
      "Owner:  scrapy\n",
      "Stars:  40856\n",
      "Repository:  https://github.com/scrapy/scrapy\n",
      "Description:  Scrapy, a fast high-level web crawling & scraping framework for Python.\n",
      "\n",
      "Name:  big-list-of-naughty-strings\n",
      "Owner:  minimaxir\n",
      "Stars:  40774\n",
      "Repository:  https://github.com/minimaxir/big-list-of-naughty-strings\n",
      "Description:  The Big List of Naughty Strings is a list of strings which have a high probability of causing issues when used as user-input data.\n",
      "\n",
      "Name:  you-get\n",
      "Owner:  soimort\n",
      "Stars:  40720\n",
      "Repository:  https://github.com/soimort/you-get\n",
      "Description:  :arrow_double_down: Dumb downloader that scrapes the web\n",
      "\n",
      "Name:  face_recognition\n",
      "Owner:  ageitgey\n",
      "Stars:  40368\n",
      "Repository:  https://github.com/ageitgey/face_recognition\n",
      "Description:  The world's simplest facial recognition api for Python and the command line\n",
      "\n",
      "Name:  superset\n",
      "Owner:  apache\n",
      "Stars:  39137\n",
      "Repository:  https://github.com/apache/superset\n",
      "Description:  Apache Superset is a Data Visualization and Data Exploration Platform\n",
      "\n",
      "Name:  faceswap\n",
      "Owner:  deepfakes\n",
      "Stars:  37310\n",
      "Repository:  https://github.com/deepfakes/faceswap\n",
      "Description:  Deepfakes Software For All\n",
      "\n",
      "Name:  shadowsocks\n",
      "Owner:  shadowsocks\n",
      "Stars:  33027\n",
      "Repository:  https://github.com/shadowsocks/shadowsocks\n",
      "Description:  None\n",
      "\n",
      "Name:  fastapi\n",
      "Owner:  tiangolo\n",
      "Stars:  32182\n",
      "Repository:  https://github.com/tiangolo/fastapi\n",
      "Description:  FastAPI framework, high performance, easy to learn, fast to code, ready for production\n",
      "\n",
      "Name:  funNLP\n",
      "Owner:  fighting41love\n",
      "Stars:  31604\n",
      "Repository:  https://github.com/fighting41love/funNLP\n",
      "Description:  中英文敏感词、语言检测、中外手机/电话归属地/运营商查询、名字推断性别、手机号抽取、身份证抽取、邮箱抽取、中日文人名库、中文缩写库、拆字词典、词汇情感值、停用词、反动词表、暴恐词表、繁简体转换、英文模拟中文发音、汪峰歌词生成器、职业名称词库、同义词库、反义词库、否定词库、汽车品牌词库、汽车零件词库、连续英文切割、各种中文词向量、公司名字大全、古诗词库、IT词库、财经词库、成语词库、地名词库、历史名人词库、诗词词库、医学词库、饮食词库、法律词库、汽车词库、动物词库、中文聊天语料、中文谣言数据、百度中文问答数据集、句子相似度匹配算法集合、bert资源、文本生成&摘要相关工具、cocoNLP信息抽取工具、国内电话号码正则匹配、清华大学XLORE:中英文跨语言百科知识图谱、清华大学人工智能技术系列报告、自然语言生成、NLU太难了系列、自动对联数据及机器人、用户名黑名单列表、罪名法务名词及分类模型、微信公众号语料、cs224n深度学习自然语言处理课程、中文手写汉字识别、中文自然语言处理 语料/数据集、变量命名神器、分词语料库+代码、任务型对话英文数据集、ASR 语音数据集 + 基于深度学习的中文语音识别系统、笑声检测器、Microsoft多语言数字/单位/如日期时间识别包、中华新华字典数据库及api(包括常用歇后语、成语、词语和汉字)、文档图谱自动生成、SpaCy 中文模型、Common Voice语音识别数据集新版、神经网络关系抽取、基于bert的命名实体识别、关键词(Keyphrase)抽取包pke、基于医疗领域知识图谱的问答系统、基于依存句法与语义角色标注的事件三元组抽取、依存句法分析4万句高质量标注数据、cnocr：用来做中文OCR的Python3包、中文人物关系知识图谱项目、中文nlp竞赛项目及代码汇总、中文字符数据、speech-aligner: 从“人声语音”及其“语言文本”产生音素级别时间对齐标注的工具、AmpliGraph: 知识图谱表示学习(Python)库：知识图谱概念链接预测、Scattertext 文本可视化(python)、语言/知识表示工具：BERT & ERNIE、中文对比英文自然语言处理NLP的区别综述、Synonyms中文近义词工具包、HarvestText领域自适应文本挖掘工具（新词发现-情感分析-实体链接等）、word2word：(Python)方便易用的多语言词-词对集：62种语言/3,564个多语言对、语音识别语料生成工具：从具有音频/字幕的在线视频创建自动语音识别(ASR)语料库、构建医疗实体识别的模型（包含词典和语料标注）、单文档非监督的关键词抽取、Kashgari中使用gpt-2语言模型、开源的金融投资数据提取工具、文本自动摘要库TextTeaser: 仅支持英文、人民日报语料处理工具集、一些关于自然语言的基本模型、基于14W歌曲知识库的问答尝试--功能包括歌词接龙and已知歌词找歌曲以及歌曲歌手歌词三角关系的问答、基于Siamese bilstm模型的相似句子判定模型并提供训练数据集和测试数据集、用Transformer编解码模型实现的根据Hacker News文章标题自动生成评论、用BERT进行序列标记和文本分类的模板代码、LitBank：NLP数据集——支持自然语言处理和计算人文学科任务的100部带标记英文小说语料、百度开源的基准信息抽取系统、虚假新闻数据集、Facebook: LAMA语言模型分析，提供Transformer-XL/BERT/ELMo/GPT预训练语言模型的统一访问接口、CommonsenseQA：面向常识的英文QA挑战、中文知识图谱资料、数据及工具、各大公司内部里大牛分享的技术文档 PDF 或者 PPT、自然语言生成SQL语句（英文）、中文NLP数据增强（EDA）工具、英文NLP数据增强工具 、基于医药知识图谱的智能问答系统、京东商品知识图谱、基于mongodb存储的军事领域知识图谱问答项目、基于远监督的中文关系抽取、语音情感分析、中文ULMFiT-情感分析-文本分类-语料及模型、一个拍照做题程序、世界各国大规模人名库、一个利用有趣中文语料库 qingyun 训练出来的中文聊天机器人、中文聊天机器人seqGAN、省市区镇行政区划数据带拼音标注、教育行业新闻语料库包含自动文摘功能、开放了对话机器人-知识图谱-语义理解-自然语言处理工具及数据、中文知识图谱：基于百度百科中文页面-抽取三元组信息-构建中文知识图谱、masr: 中文语音识别-提供预训练模型-高识别率、Python音频数据增广库、中文全词覆盖BERT及两份阅读理解数据、ConvLab：开源多域端到端对话系统平台、中文自然语言处理数据集、基于最新版本rasa搭建的对话系统、基于TensorFlow和BERT的管道式实体及关系抽取、一个小型的证券知识图谱/知识库、复盘所有NLP比赛的TOP方案、OpenCLaP：多领域开源中文预训练语言模型仓库、UER：基于不同语料+编码器+目标任务的中文预训练模型仓库、中文自然语言处理向量合集、基于金融-司法领域(兼有闲聊性质)的聊天机器人、g2pC：基于上下文的汉语读音自动标记模块、Zincbase 知识图谱构建工具包、诗歌质量评价/细粒度情感诗歌语料库、快速转化「中文数字」和「阿拉伯数字」、百度知道问答语料库、基于知识图谱的问答系统、jieba_fast 加速版的jieba、正则表达式教程、中文阅读理解数据集、基于BERT等最新语言模型的抽取式摘要提取、Python利用深度学习进行文本摘要的综合指南、知识图谱深度学习相关资料整理、维基大规模平行文本语料、StanfordNLP 0.2.0：纯Python版自然语言处理包、NeuralNLP-NeuralClassifier：腾讯开源深度学习文本分类工具、端到端的封闭域对话系统、中文命名实体识别：NeuroNER vs. BertNER、新闻事件线索抽取、2019年百度的三元组抽取比赛：“科学空间队”源码、基于依存句法的开放域文本知识三元组抽取和知识库构建、中文的GPT2训练代码、ML-NLP - 机器学习(Machine Learning)NLP面试中常考到的知识点和代码实现、nlp4han:中文自然语言处理工具集(断句/分词/词性标注/组块/句法分析/语义分析/NER/N元语法/HMM/代词消解/情感分析/拼写检查、XLM：Facebook的跨语言预训练语言模型、用基于BERT的微调和特征提取方法来进行知识图谱百度百科人物词条属性抽取、中文自然语言处理相关的开放任务-数据集-当前最佳结果、CoupletAI - 基于CNN+Bi-LSTM+Attention 的自动对对联系统、抽象知识图谱、MiningZhiDaoQACorpus - 580万百度知道问答数据挖掘项目、brat rapid annotation tool: 序列标注工具、大规模中文知识图谱数据：1.4亿实体、数据增强在机器翻译及其他nlp任务中的应用及效果、allennlp阅读理解:支持多种数据和模型、PDF表格数据提取工具 、 Graphbrain：AI开源软件库和科研工具，目的是促进自动意义提取和文本理解以及知识的探索和推断、简历自动筛选系统、基于命名实体识别的简历自动摘要、中文语言理解测评基准，包括代表性的数据集&基准模型&语料库&排行榜、树洞 OCR 文字识别 、从包含表格的扫描图片中识别表格和文字、语声迁移、Python口语自然语言处理工具集(英文)、 similarity：相似度计算工具包，java编写、海量中文预训练ALBERT模型 、Transformers 2.0 、基于大规模音频数据集Audioset的音频增强 、Poplar：网页版自然语言标注工具、图片文字去除，可用于漫画翻译 、186种语言的数字叫法库、Amazon发布基于知识的人-人开放领域对话数据集 、中文文本纠错模块代码、繁简体转换 、 Python实现的多种文本可读性评价指标、类似于人名/地名/组织机构名的命名体识别数据集 、东南大学《知识图谱》研究生课程(资料)、. 英文拼写检查库 、 wwsearch是企业微信后台自研的全文检索引擎、CHAMELEON：深度学习新闻推荐系统元架构 、 8篇论文梳理BERT相关模型进展与反思、DocSearch：免费文档搜索引擎、 LIDA：轻量交互式对话标注工具 、aili - the fastest in-memory index in the East 东半球最快并发索引 、知识图谱车音工作项目、自然语言生成资源大全 、中日韩分词库mecab的Python接口库、中文文本摘要/关键词提取、汉字字符特征提取器 (featurizer)，提取汉字的特征（发音特征、字形特征）用做深度学习的特征、中文生成任务基准测评 、中文缩写数据集、中文任务基准测评 - 代表性的数据集-基准(预训练)模型-语料库-baseline-工具包-排行榜、PySS3：面向可解释AI的SS3文本分类器机器可视化工具 、中文NLP数据集列表、COPE - 格律诗编辑程序、doccano：基于网页的开源协同多语言文本标注工具 、PreNLP：自然语言预处理库、简单的简历解析器，用来从简历中提取关键信息、用于中文闲聊的GPT2模型：GPT2-chitchat、基于检索聊天机器人多轮响应选择相关资源列表(Leaderboards、Datasets、Papers)、(Colab)抽象文本摘要实现集锦(教程 、词语拼音数据、高效模糊搜索工具、NLP数据增广资源集、微软对话机器人框架 、 GitHub Typo Corpus：大规模GitHub多语言拼写错误/语法错误数据集、TextCluster：短文本聚类预处理模块 Short text cluster、面向语音识别的中文文本规范化、BLINK：最先进的实体链接库、BertPunc：基于BERT的最先进标点修复模型、Tokenizer：快速、可定制的文本词条化库、中文语言理解测评基准，包括代表性的数据集、基准(预训练)模型、语料库、排行榜、spaCy 医学文本挖掘与信息提取 、 NLP任务示例项目代码集、 python拼写检查库、chatbot-list - 行业内关于智能客服、聊天机器人的应用和架构、算法分享和介绍、语音质量评价指标(MOSNet, BSSEval, STOI, PESQ, SRMR)、 用138GB语料训练的法文RoBERTa预训练语言模型 、BERT-NER-Pytorch：三种不同模式的BERT中文NER实验、无道词典 - 有道词典的命令行版本，支持英汉互查和在线查询、2019年NLP亮点回顾、 Chinese medical dialogue data 中文医疗对话数据集 、最好的汉字数字(中文数字)-阿拉伯数字转换工具、 基于百科知识库的中文词语多词义/义项获取与特定句子词语语义消歧、awesome-nlp-sentiment-analysis - 情感分析、情绪原因识别、评价对象和评价词抽取、LineFlow：面向所有深度学习框架的NLP数据高效加载器、中文医学NLP公开资源整理 、MedQuAD：(英文)医学问答数据集、将自然语言数字串解析转换为整数和浮点数、Transfer Learning in Natural Language Processing (NLP) 、面向语音识别的中文/英文发音辞典、Tokenizers：注重性能与多功能性的最先进分词器、CLUENER 细粒度命名实体识别 Fine Grained Named Entity Recognition、 基于BERT的中文命名实体识别、中文谣言数据库、NLP数据集/基准任务大列表、nlp相关的一些论文及代码, 包括主题模型、词向量(Word Embedding)、命名实体识别(NER)、文本分类(Text Classificatin)、文本生成(Text Generation)、文本相似性(Text Similarity)计算等，涉及到各种与nlp相关的算法，基于keras和tensorflow 、Python文本挖掘/NLP实战示例、 Blackstone：面向非结构化法律文本的spaCy pipeline和NLP模型通过同义词替换实现文本“变脸” 、中文 预训练 ELECTREA 模型: 基于对抗学习 pretrain Chinese Model 、albert-chinese-ner - 用预训练语言模型ALBERT做中文NER 、基于GPT2的特定主题文本生成/文本增广、开源预训练语言模型合集、多语言句向量包、编码、标记和实现：一种可控高效的文本生成方法、 英文脏话大列表 、attnvis：GPT2、BERT等transformer语言模型注意力交互可视化、CoVoST：Facebook发布的多语种语音-文本翻译语料库，包括11种语言(法语、德语、荷兰语、俄语、西班牙语、意大利语、土耳其语、波斯语、瑞典语、蒙古语和中文)的语音、文字转录及英文译文、Jiagu自然语言处理工具 - 以BiLSTM等模型为基础，提供知识图谱关系抽取 中文分词 词性标注 命名实体识别 情感分析 新词发现 关键词 文本摘要 文本聚类等功能、用unet实现对文档表格的自动检测，表格重建、NLP事件提取文献资源列表 、 金融领域自然语言处理研究资源大列表、CLUEDatasetSearch - 中英文NLP数据集：搜索所有中文NLP数据集，附常用英文NLP数据集 、medical_NER - 中文医学知识图谱命名实体识别 、(哈佛)讲因果推理的免费书、知识图谱相关学习资料/数据集/工具资源大列表、Forte：灵活强大的自然语言处理pipeline工具集 、Python字符串相似性算法库、PyLaia：面向手写文档分析的深度学习工具包、TextFooler：针对文本分类/推理的对抗文本生成模块、Haystack：灵活、强大的可扩展问答(QA)框架、中文关键短语抽取工具\n",
      "\n",
      "Name:  interview_internal_reference\n",
      "Owner:  0voice\n",
      "Stars:  31561\n",
      "Repository:  https://github.com/0voice/interview_internal_reference\n",
      "Description:  2021年最新总结，阿里，腾讯，百度，美团，头条等技术面试题目，以及答案，专家出题人分析汇总。\n",
      "\n",
      "Name:  CppCoreGuidelines\n",
      "Owner:  isocpp\n",
      "Stars:  31024\n",
      "Repository:  https://github.com/isocpp/CppCoreGuidelines\n",
      "Description:  The C++ Core Guidelines are a set of tried-and-true guidelines, rules, and best practices about coding in C++\n",
      "\n",
      "Name:  localstack\n",
      "Owner:  localstack\n",
      "Stars:  30762\n",
      "Repository:  https://github.com/localstack/localstack\n",
      "Description:  💻  A fully functional local AWS cloud stack. Develop and test your cloud & Serverless apps offline!\n",
      "\n",
      "Name:  pandas\n",
      "Owner:  pandas-dev\n",
      "Stars:  30080\n",
      "Repository:  https://github.com/pandas-dev/pandas\n",
      "Description:  Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more\n",
      "\n",
      "Name:  12306\n",
      "Owner:  testerSunshine\n",
      "Stars:  30060\n",
      "Repository:  https://github.com/testerSunshine/12306\n",
      "Description:  12306智能刷票，订票\n"
     ]
    }
   ],
   "source": [
    "# python_repos.py\n",
    "\n",
    "import requests\n",
    "\n",
    "# Make an API call and store the response\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "r = requests.get(url)\n",
    "print(\"Status code:\", r.status_code)\n",
    "# Store API response in a variable\n",
    "response_dict = r.json()\n",
    "\n",
    "# Show the keys in the dictionary\n",
    "# print(response_dict.keys())\n",
    "\n",
    "# Show the total number of repositories\n",
    "print(\"Total repositories:\", response_dict['total_count'])\n",
    "\n",
    "# Explore  information about the repositories\n",
    "repo_dicts = response_dict['items']\n",
    "print(\"Repositories returned:\", len(repo_dicts))\n",
    "\n",
    "# Examine the first repository\n",
    "repo_dict = repo_dicts[0]\n",
    "# Show how many key there are and what they are\n",
    "#print(\"\\nKeys:\", len(repo_dict))\n",
    "#for key in sorted(repo_dict.keys()):\n",
    "#    print(key)\n",
    "# Print selected info (based on keys) from the first repository\n",
    "print(\"\\nSelected info about the first repository:\")\n",
    "print(\"Name: \", repo_dict['name'])\n",
    "print('Owner: ', repo_dict['owner']['login'])\n",
    "print('Stars: ', repo_dict['stargazers_count'])\n",
    "print('Repository: ', repo_dict['html_url'])\n",
    "print('Created: ', repo_dict['created_at'])\n",
    "print('Updated: ', repo_dict['updated_at'])\n",
    "print('Description: ', repo_dict['description'])\n",
    "\n",
    "# Print selected info for each repository\n",
    "print(\"\\nSelected info about each repository:\")\n",
    "for repo_dict in repo_dicts:\n",
    "    print(\"\\nName: \", repo_dict['name'])\n",
    "    print('Owner: ', repo_dict['owner']['login'])\n",
    "    print('Stars: ', repo_dict['stargazers_count'])\n",
    "    print('Repository: ', repo_dict['html_url'])\n",
    "    print('Description: ', repo_dict['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Total repositories: 7454277\n"
     ]
    }
   ],
   "source": [
    "# python_repos.py - Visualizing Repositories Using Pygal\n",
    "\n",
    "#import requests\n",
    "import pygal\n",
    "from pygal.style import LightColorizedStyle as LCS, LightenStyle as LS\n",
    "\n",
    "# Make an API call and store the response\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "r = requests.get(url)\n",
    "print(\"Status code:\", r.status_code)\n",
    "# Store API response in a variable\n",
    "response_dict = r.json()\n",
    "\n",
    "# Show the total number of repositories\n",
    "print(\"Total repositories:\", response_dict['total_count'])\n",
    "\n",
    "# Explore  information about the repositories\n",
    "repo_dicts = response_dict['items']\n",
    "\n",
    "# Create lists for repository names and stars\n",
    "names, stars = [],[]\n",
    "for repo_dict in repo_dicts:\n",
    "    names.append(repo_dict['name'])\n",
    "    stars.append(repo_dict['stargazers_count'])\n",
    "\n",
    "# Make visualization\n",
    "# Create style objects\n",
    "my_style = LS('#333366', base_style=LCS)\n",
    "my_style.title_font_size = 24\n",
    "my_style.label_font_size = 14\n",
    "my_style.major_label_font_size = 20\n",
    "\n",
    "# Define parameters for Pygal's Config class\n",
    "my_config = pygal.Config()\n",
    "my_config.x_label_rotation=45\n",
    "my_config.show_legend = False\n",
    "my_config.truncate_label = 15\n",
    "my_config.show_y_guides = False\n",
    "my_config.width = 1000\n",
    "\n",
    "# Use style objects and configuration in Bar\n",
    "chart = pygal.Bar(my_config, style=my_style)\n",
    "chart.title = 'Most-Starred Python Projects on GitHub'\n",
    "chart.x_labels = names\n",
    "\n",
    "chart.add('',stars)\n",
    "chart.render_to_file('python_repos.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Tooltips\n",
    "\n",
    "# import pygal\n",
    "# from pygal.style import LightColorizedStyle as LCS, LightenedStyle as LS\n",
    "\n",
    "my_style = LS('#333366', base_style=LCS)\n",
    "chart = pygal.Bar(style=my_style, x_label_rotation=45, show_legend=False)\n",
    "chart.title = 'Python Projects'\n",
    "chart.x_labels = ['httpie', 'django', 'flask']\n",
    "\n",
    "plot_dicts = [\n",
    "    {'value': 16101, 'label': 'Description of httpie'},\n",
    "    {'value': 15028, 'label': 'Description of django'},\n",
    "    {'value': 14798, 'label': 'Description of flask'},\n",
    "]\n",
    "\n",
    "chart.add('', plot_dicts)\n",
    "chart.render_to_file('bar_descriptions.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Total repositories: 7454302\n"
     ]
    }
   ],
   "source": [
    "# python_repos.py - Plotting the Data\n",
    "\n",
    "#import requests\n",
    "# import pygal\n",
    "# from pygal.style import LightColorizedStyle as LCS, LightenStyle as LS\n",
    "\n",
    "# Make an API call and store the response\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "r = requests.get(url)\n",
    "print(\"Status code:\", r.status_code)\n",
    "# Store API response in a variable\n",
    "response_dict = r.json()\n",
    "\n",
    "# Show the total number of repositories\n",
    "print(\"Total repositories:\", response_dict['total_count'])\n",
    "\n",
    "# Explore  information about the repositories\n",
    "repo_dicts = response_dict['items']\n",
    "\n",
    "# Create lists for repository names and stars\n",
    "names, plot_dicts = [],[]\n",
    "for repo_dict in repo_dicts:\n",
    "    names.append(repo_dict['name'])\n",
    "    \n",
    "    # Get the project description, if one is available\n",
    "    description = repo_dict['description']\n",
    "    if not description:\n",
    "        description = \"No description provided\"\n",
    "        \n",
    "    plot_dict = {\n",
    "        'value': repo_dict['stargazers_count'],\n",
    "        'label': description,\n",
    "        # Add link to label\n",
    "        'xlink': repo_dict['html_url'],\n",
    "    }\n",
    "    plot_dicts.append(plot_dict)\n",
    "\n",
    "# Make visualization\n",
    "# Create style objects\n",
    "my_style = LS('#333366', base_style=LCS)\n",
    "my_style.title_font_size = 24\n",
    "my_style.label_font_size = 14\n",
    "my_style.major_label_font_size = 20\n",
    "\n",
    "# Define parameters for Pygal's Config class\n",
    "my_config = pygal.Config()\n",
    "my_config.x_label_rotation=45\n",
    "my_config.show_legend = False\n",
    "my_config.truncate_label = 15\n",
    "my_config.show_y_guides = False\n",
    "my_config.width = 1000\n",
    "\n",
    "# Use style objects and configuration in Bar\n",
    "chart = pygal.Bar(my_config, style=my_style)\n",
    "chart.title = 'Most-Starred Python Projects on GitHub'\n",
    "chart.x_labels = names\n",
    "\n",
    "chart.add('',plot_dicts)\n",
    "chart.render_to_file('python_repos2.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "\n",
      "Title: 80% of orgs that paid the ransom were hit again\n",
      "Discussion link: http://news.ycombinator.com/item?id=27552611\n",
      "Comments: 308\n",
      "\n",
      "Title: Starlink dishes go into “thermal shutdown” once they hit 122° Fahrenheit\n",
      "Discussion link: http://news.ycombinator.com/item?id=27526074\n",
      "Comments: 210\n",
      "\n",
      "Title: Oregon Has Legalized Human Composting\n",
      "Discussion link: http://news.ycombinator.com/item?id=27549652\n",
      "Comments: 190\n",
      "\n",
      "Title: Nuclear Power at McMurdo Station, Antarctica\n",
      "Discussion link: http://news.ycombinator.com/item?id=27549484\n",
      "Comments: 175\n",
      "\n",
      "Title: ZFS fans, rejoice – RAIDz expansion will be a thing soon\n",
      "Discussion link: http://news.ycombinator.com/item?id=27537045\n",
      "Comments: 123\n",
      "\n",
      "Title: AMD vs. Intel CPU Market Share\n",
      "Discussion link: http://news.ycombinator.com/item?id=27553451\n",
      "Comments: 119\n",
      "\n",
      "Title: Launch HN: Hedgehog (YC S21) – Cryptocurrency Portfolio Manager\n",
      "Discussion link: http://news.ycombinator.com/item?id=27550255\n",
      "Comments: 108\n",
      "\n",
      "Title: Mars helicopter employs advanced control techniques to survive in-flight anomaly\n",
      "Discussion link: http://news.ycombinator.com/item?id=27553718\n",
      "Comments: 68\n",
      "\n",
      "Title: Prossimo – Memory safety for the Internet's most critical infrastructure\n",
      "Discussion link: http://news.ycombinator.com/item?id=27550703\n",
      "Comments: 62\n",
      "\n",
      "Title: Can programming be liberated from the von Neumann style? (1978)\n",
      "Discussion link: http://news.ycombinator.com/item?id=27554355\n",
      "Comments: 52\n",
      "\n",
      "Title: StreetComplete: Easy to use editor of OpenStreetMap data\n",
      "Discussion link: http://news.ycombinator.com/item?id=27549300\n",
      "Comments: 45\n",
      "\n",
      "Title: BBC Programme Index: 9M listings and 221k playable programmes\n",
      "Discussion link: http://news.ycombinator.com/item?id=27555918\n",
      "Comments: 43\n",
      "\n",
      "Title: SNES – Super Mario World Widescreen\n",
      "Discussion link: http://news.ycombinator.com/item?id=27554765\n",
      "Comments: 31\n",
      "\n",
      "Title: The UX of video game tutorials\n",
      "Discussion link: http://news.ycombinator.com/item?id=27525557\n",
      "Comments: 31\n",
      "\n",
      "Title: Widescreen Gaming in the 90s\n",
      "Discussion link: http://news.ycombinator.com/item?id=27548296\n",
      "Comments: 20\n",
      "\n",
      "Title: Minimum Viable Self\n",
      "Discussion link: http://news.ycombinator.com/item?id=27556092\n",
      "Comments: 19\n",
      "\n",
      "Title: Janet Malcolm has died\n",
      "Discussion link: http://news.ycombinator.com/item?id=27545827\n",
      "Comments: 13\n",
      "\n",
      "Title: In 1850, Ignaz Semmelweis saved lives with three words: wash your hands (2015)\n",
      "Discussion link: http://news.ycombinator.com/item?id=27541409\n",
      "Comments: 9\n",
      "\n",
      "Title: Excess deaths and SARS-CoV2 vaccinations in Scotland\n",
      "Discussion link: http://news.ycombinator.com/item?id=27548694\n",
      "Comments: 8\n",
      "\n",
      "Title: America’s weirdest guidebooks were funded by the government\n",
      "Discussion link: http://news.ycombinator.com/item?id=27556077\n",
      "Comments: 6\n",
      "\n",
      "Title: Adafruit interviews Siemens SupplyFrame, the future of Hackaday, Tindie and more\n",
      "Discussion link: http://news.ycombinator.com/item?id=27556552\n",
      "Comments: 5\n",
      "\n",
      "Title: Vespucci – OpenStreetMap Editor for Android\n",
      "Discussion link: http://news.ycombinator.com/item?id=27554789\n",
      "Comments: 5\n",
      "\n",
      "Title: Kazakhstan’s forest is the birthplace of modern apples\n",
      "Discussion link: http://news.ycombinator.com/item?id=27547342\n",
      "Comments: 5\n",
      "\n",
      "Title: Confessions of a bitter cripple (2015)\n",
      "Discussion link: http://news.ycombinator.com/item?id=27556381\n",
      "Comments: 5\n",
      "\n",
      "Title: CatMeows: A Publicly-Available Dataset of Cat Vocalizations\n",
      "Discussion link: http://news.ycombinator.com/item?id=27556544\n",
      "Comments: 2\n",
      "\n",
      "Title: Verkle Trees\n",
      "Discussion link: http://news.ycombinator.com/item?id=27554404\n",
      "Comments: 2\n",
      "\n",
      "Title: Human Rapamycin Longevity Clinical Trials Begin\n",
      "Discussion link: http://news.ycombinator.com/item?id=27556564\n",
      "Comments: 1\n",
      "\n",
      "Title: Fly Straight, Dammit (2019)\n",
      "Discussion link: http://news.ycombinator.com/item?id=27555904\n",
      "Comments: 1\n",
      "\n",
      "Title: EasyPost is building the logistics platform for ecommerce\n",
      "Discussion link: http://news.ycombinator.com/item?id=27554998\n",
      "Comments: 0\n",
      "\n",
      "Title: Thoughts on managing engineering teams\n",
      "Discussion link: http://news.ycombinator.com/item?id=27544339\n",
      "Comments: 0\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "# Make an API call and store the response\n",
    "url= 'https://hacker-news.firebaseio.com/v0/topstories.json'\n",
    "r = requests.get(url)\n",
    "print('Status code:', r.status_code)\n",
    "\n",
    "# Process information about each submission\n",
    "# Convert text to Python list\n",
    "submission_ids = r.json()\n",
    "submission_dicts = []\n",
    "# Loop through top 30 submissions\n",
    "for submission_id in submission_ids[:30]:\n",
    "    # Make a separate API call for each submission\n",
    "    url = ('https://hacker-news.firebaseio.com/v0/item/' + str(submission_id) + '.json')\n",
    "    submission_r = requests.get(url)\n",
    "    print(submission_r.status_code)\n",
    "    response_dict = submission_r.json()\n",
    "    \n",
    "    # Create dictionary for submission title and link to discussion page\n",
    "    submission_dict = {\n",
    "        'title': response_dict['title'],\n",
    "        'link': 'http://news.ycombinator.com/item?id=' + str(submission_id),\n",
    "        # Store comments in dictionary. Returns 0 if no key is present\n",
    "        'comments': response_dict.get('descendants',0)\n",
    "        }\n",
    "    submission_dicts.append(submission_dict)\n",
    "\n",
    "# Sort submission list\n",
    "submission_dicts = sorted(submission_dicts, key=itemgetter('comments'),reverse=True)\n",
    "\n",
    "# Print out info for the top submissions\n",
    "for submission_dict in submission_dicts:\n",
    "    print(\"\\nTitle:\", submission_dict['title'])\n",
    "    print(\"Discussion link:\", submission_dict['link'])\n",
    "    print(\"Comments:\", submission_dict['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
